{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29349f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import wandb\n",
    "from wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc, plot_calibration_curve, plot_summary_metrics, plot_precision_recall, plot_feature_importances\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#핫덱대체\n",
    "#근로기간 Unknown <<< 나머지 학습해서 결과 뽑기?\n",
    "\n",
    "# 근로기간\n",
    "# 10+ years    31585\n",
    "# 2 years       8450\n",
    "# < 1 year      7774\n",
    "# 3 years       7581\n",
    "# 1 year        6249\n",
    "# Unknown       5671 << 5.8% 정도\n",
    "# 5 years       5665\n",
    "# 4 years       5588\n",
    "# 8 years       4888\n",
    "# 6 years       3874\n",
    "# 7 years       3814\n",
    "# 9 years       3744\n",
    "# 10+years       896\n",
    "# <1 year        370\n",
    "# 3               89\n",
    "# 1 years         56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd873a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: valid score: 0.9010355506977307\n",
    "# 1: valid score: 0.9050661554969067\n",
    "# 2: valid score: 0.901121413402887\n",
    "# 3: valid score: 0.9037491766255578\n",
    "# 4: valid score: 0.9032539417389811\n",
    "# 5: valid score: 0.9051953433118983\n",
    "# 6: valid score: 0.9071750113042895\n",
    "# 7: valid score: 0.9024298085584201\n",
    "# 8: \n",
    "# 9: \n",
    "# 10: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_int(string):\n",
    "    num = re.sub(r'[^0-9]', '', string)\n",
    "    if num:\n",
    "        return num\n",
    "    else:\n",
    "        return \"6\"\n",
    "\n",
    "def extract_categorical_columns(df):\n",
    "    data = []\n",
    "    for e, i in enumerate(df.columns):\n",
    "        if df[i].dtypes == 'object':\n",
    "            data.append(i)\n",
    "    return data\n",
    "\n",
    "def ordinal_encoding(train_df, test_df, categorical_columns):\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    train, test = train_df.copy(), test_df.copy()\n",
    "    data = {}\n",
    "    for col in categorical_columns:\n",
    "        ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        ordinal_encoder.fit(train[col].values.reshape(-1, 1))\n",
    "        train[col] = ordinal_encoder.transform(train[col].values.reshape(-1, 1)).reshape(-1)\n",
    "        if col in test:\n",
    "            test[col] = ordinal_encoder.transform(test[col].values.reshape(-1, 1)).reshape(-1)\n",
    "        data[col] = ordinal_encoder\n",
    "    return train, test, data\n",
    "\n",
    "def sep_ml_xy(df, target):\n",
    "    y = df[target]\n",
    "    x = df.drop(columns=target)\n",
    "    return x, y\n",
    "\n",
    "def ml_train_valid(model, metric, metric_options, train_data, train_target, test_data, test_target):\n",
    "    model = model.fit(train_data, train_target)\n",
    "    pred = model.predict(test_data)\n",
    "    evaluate = metric(test_target, pred, **metric_options)\n",
    "    return pred, evaluate, model\n",
    "\n",
    "def ml_predict(model, test_data):\n",
    "    pred = model.predict(test_data)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe376ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['ID'])\n",
    "test = test.drop(columns=['ID'])\n",
    "\n",
    "for span in [\"근로기간\"]:\n",
    "    train[span] = train[span].apply(lambda x: int(only_int(x)))\n",
    "    test[span] = test[span].apply(lambda x: int(only_int(x)))\n",
    "\n",
    "for span in [\"대출기간\"]:\n",
    "    train[span] = train[span].apply(lambda x: int(int(only_int(x))/12))\n",
    "    test[span] = test[span].apply(lambda x: int(int(only_int(x))/12))\n",
    "    \n",
    "for span in [\"총상환이자\", \"총연체금액\", \"연체계좌수\"]:\n",
    "    train[span] = train[span].apply(lambda x: int(x))\n",
    "    test[span] = test[span].apply(lambda x: int(x))\n",
    "# display(train.head(3), test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대출금액, 대출기간, 근로기간, 주택소유상태, 연간소득, 부채_대비_소득_비율, 총계좌수, 대출목적, 최근_2년간_연체_횟수, 총상환원금, 총상환이자, 총연체금액, 연쳬계좌수\n",
    "\n",
    "def add_var(train):\n",
    "    train['총상환원금+총상환이자-총연체금액/대출금액'] = (train['총상환원금'] + train['총상환이자'] - train['총연체금액']) / train['대출금액'] * 100\n",
    "    # train['대출금액/대출기간/연간소득 %'] = train['대출금액'] / train['대출기간'] / train['연간소득'] * 100\n",
    "    train['총상환원금/대출금액'] = (train['총상환원금']) / train['대출금액'] * 100\n",
    "    train['대출금액/대출기간'] = train['대출금액'] / train['대출기간'] * 100\n",
    "    train['대출금액/연간소득'] = train['대출금액'] / train['연간소득'] * 100\n",
    "    # train['총연체금액/대출금액 %'] = train['총연체금액'] / train['대출금액'] * 100\n",
    "    train['총상환이자/총상환원금'] = train['총상환이자'] / train['총상환원금'] * 100\n",
    "    train['근로기간/대출기간'] = train['근로기간'] / train['대출기간'] * 100\n",
    "    train['연간소득/대출기간'] = train['연간소득'] / train['대출기간'] * 100\n",
    "    train['최근_2년간_연체_횟수/대출기간'] = train['최근_2년간_연체_횟수'] / train['대출기간'] *12 * 100\n",
    "    train['총상환원금/대출기간'] = train['총상환원금'] / train['대출기간'] * 100\n",
    "    train['총상환이자/대출기간'] = train['총상환이자'] / train['대출기간'] * 100\n",
    "    # train['총연체금액/대출기간 %'] = train['총연체금액'] / train['대출기간'] * 100\n",
    "    train['근로기간*연간소득'] = train['근로기간'] * train['연간소득']\n",
    "    train['주택소유상태_대출목적'] = train['주택소유상태'] + \"_\" + train['대출목적']\n",
    "    # train['연체계좌수/총계좌수'] = train['연체계좌수'] / train['총계좌수']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2145c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_var(train):\n",
    "    train = train.drop(columns=['총연체금액', '연체계좌수', '최근_2년간_연체_횟수'])\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bfbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_process(train):\n",
    "    train.loc[train['총상환원금']==0,'총상환이자/총상환원금'] = 0\n",
    "\n",
    "    train['연간소득(만)'] = train['연간소득']/10000\n",
    "    train['대출금액(만)'] = train['대출금액']/10000\n",
    "    \n",
    "    train['연간소득(만).편차^2'] =  (train['연간소득(만)'] - train['연간소득(만)'].mean())**2\n",
    "    train['연간소득(만).log'] = train['연간소득(만)'].apply(np.log1p)\n",
    "    train['대출금액(만).편차^2'] =  (train['대출금액(만)'] - train['대출금액(만)'].mean())**2\n",
    "    train['대출금액(만).log'] = train['대출금액(만)'].apply(np.log1p)\n",
    "    \n",
    "    train['근로기간.log'] = train['근로기간'].apply(np.log1p)\n",
    "    train['대출기간.log'] = train['대출기간'].apply(np.log1p)\n",
    "    \n",
    "    # train['총상환이자/총상환원금.편차^2'] = (train['총상환이자/총상환원금'] - train['총상환이자/총상환원금'].mean())**2\n",
    "    train['총상환이자/총상환원금.log'] = train['총상환이자/총상환원금'].apply(np.log1p)\n",
    "\n",
    "    train['총상환원금/대출금액.편차^2'] = (train['총상환원금/대출금액'] - train['총상환원금/대출금액'].mean())**2\n",
    "    train['총상환원금/대출금액.log'] = train['총상환원금/대출금액'].apply(np.log1p)\n",
    "\n",
    "    train['부채_대비_소득_비율.편차^2'] = (train['부채_대비_소득_비율'] - train['부채_대비_소득_비율'].mean())**2\n",
    "    train['부채_대비_소득_비율.log'] = train['부채_대비_소득_비율'].apply(np.log1p)\n",
    "\n",
    "    # train['대출금액/연간소득.편차^2'] = (train['대출금액/연간소득'] - train['대출금액/연간소득'].mean())**2\n",
    "    train['대출금액/연간소득.log'] = train['대출금액/연간소득'].apply(np.log1p)\n",
    "\n",
    "    train['총상환원금+총상환이자-총연체금액/대출금액.편차^2'] = (train['총상환원금+총상환이자-총연체금액/대출금액'] - train['총상환원금+총상환이자-총연체금액/대출금액'].mean())**2\n",
    "    train['총상환원금+총상환이자-총연체금액/대출금액.log'] = train['총상환원금+총상환이자-총연체금액/대출금액'].apply(np.log1p)\n",
    "\n",
    "    train['근로기간*연간소득.편차^2'] = (train['근로기간*연간소득'] - train['근로기간*연간소득'].mean())**2\n",
    "    train['근로기간*연간소득.log'] = train['근로기간*연간소득'].apply(np.log1p)\n",
    "\n",
    "    train['연간소득/대출기간.편차^2'] = (train['연간소득/대출기간'] - train['연간소득/대출기간'].mean())**2\n",
    "    train['연간소득/대출기간.log'] = train['연간소득/대출기간'].apply(np.log1p)\n",
    "\n",
    "    train['대출금액/대출기간.편차^2'] = (train['대출금액/대출기간'] - train['대출금액/대출기간'].mean())**2\n",
    "    train['대출금액/대출기간.log'] = train['대출금액/대출기간'].apply(np.log1p)\n",
    "\n",
    "    train['총상환이자/대출기간.편차^2'] = (train['총상환이자/대출기간'] - train['총상환이자/대출기간'].mean())**2\n",
    "    train['총상환이자/대출기간.log'] = train['총상환이자/대출기간'].apply(np.log1p)\n",
    "\n",
    "    train['총상환이자.편차^2'] = (train['총상환이자'] - train['총상환이자'].mean())**2\n",
    "    train['총상환이자.log'] = train['총상환이자'].apply(np.log1p)\n",
    "\n",
    "    # train['최근_2년간_연체_횟수/대출기간.편차^2'] = (train['최근_2년간_연체_횟수/대출기간'] - train['최근_2년간_연체_횟수/대출기간'].mean())**2\n",
    "    # train['최근_2년간_연체_횟수/대출기간.log'] = train['최근_2년간_연체_횟수/대출기간'].apply(np.log1p)\n",
    "\n",
    "    # train['총상환원금/대출기간.편차^2'] = (train['총상환원금/대출기간'] - train['총상환원금/대출기간'].mean())**2\n",
    "    # train['총상환원금/대출기간.log'] = train['총상환원금/대출기간'].apply(np.log1p)\n",
    "\n",
    "    train['총상환원금.편차^2'] = (train['총상환원금'] - train['총상환원금'].mean())**2\n",
    "    # train['총상환원금.log'] = train['총상환원금'].apply(np.log1p)\n",
    "\n",
    "    # train['최근_2년간_연체_횟수.편차^2'] = (train['최근_2년간_연체_횟수'] - train['최근_2년간_연체_횟수'].mean())**2\n",
    "    # train['최근_2년간_연체_횟수.log'] = train['최근_2년간_연체_횟수'].apply(np.log1p)\n",
    "\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ad07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_var(train)\n",
    "test = add_var(test)\n",
    "\n",
    "train = drop_var(train)\n",
    "test = drop_var(test)\n",
    "\n",
    "train = numeric_process(train)\n",
    "test = numeric_process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09eb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['주택소유상태', '대출목적', '주택소유상태_대출목적']\n",
    "\n",
    "for i in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train[i]) \n",
    "    train[i]=le.transform(train[i])\n",
    "    \n",
    "    for case in np.unique(test[i]):\n",
    "        if case not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, case) \n",
    "    test[i]=le.transform(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04088b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_scale = ['대출금액','연간소득', '부채_대비_소득_비율', '총상환원금', '총상환이자', '총연체금액']\n",
    "# 대출금액, 대출기간, 근로기간, 주택소유상태, 연간소득, 부채_대비_소득_비율, 총계좌수, 대출목적, 최근_2년간_연체_횟수, 총상환원금, 총상환이자, 총연체금액, 연쳬계좌수\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "# train[columns_to_scale] = scaler.fit_transform(train[columns_to_scale])\n",
    "# test[columns_to_scale] = scaler.transform(test[columns_to_scale])\n",
    "\n",
    "display(train.head(5), test.head(5))\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474da70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "categorical_columns = extract_categorical_columns(train)\n",
    "train, test, ord_dict = ordinal_encoding(train, test, categorical_columns)\n",
    "train_x, train_y = sep_ml_xy(train, \"대출등급\")\n",
    "train_x, valid_x, train_y, valid_y = tts(train_x, train_y, train_size=0.8, shuffle=True, random_state=0)\n",
    "\n",
    "# model = CatBoostClassifier()\n",
    "# model = model.fit(train_x, train_y)\n",
    "model = CatBoostClassifier(n_estimators=1000, learning_rate=0.1, max_depth=10, verbose=100, task_type='GPU', bootstrap_type ='Bernoulli')\n",
    "model = model.fit(train_x, train_y, cat_features=categorical_features, early_stopping_rounds=50, eval_set=[(valid_x, valid_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = model.get_params()\n",
    "# [n_estimators=1000, learning_rate=0.1, max_depth=10, verbose=100, task_type='GPU', bootstrap_type ='Bernoulli']\n",
    "y_pred = model.predict(valid_x)\n",
    "y_probas = model.predict_proba(valid_x)\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "wandb.init(project='Dacon-loan-rating', config=model_params)\n",
    "\n",
    "# wandb.config.update({\n",
    "#                     \"test_size\" : 0.2,\n",
    "#                     \"train_len\" : len(train_x),\n",
    "#                     \"test_len\" : len(valid_x),\n",
    "#                     \"learning_rate\" : (0.001, 0.3),\n",
    "#                     \"max_depth\" : (5, 15),\n",
    "#                     })\n",
    "\n",
    "# plot_class_proportions(train_y, valid_y, '대출등급')\n",
    "# plot_learning_curve(model, train_x, train_y)\n",
    "# plot_roc(valid_y, y_probas, '대출등급')\n",
    "# plot_precision_recall(valid_y, y_probas, '대출등급')\n",
    "# plot_feature_importances(model, train_x.columns, \"Feature Importances\")\n",
    "# # plot_calibration_curve(model, train_x, train_y, \"CatBoostClassifier\")\n",
    "# plot_summary_metrics(model, train_x, train_y, valid_x, valid_y)\n",
    "# # wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984478fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # sweep 설정\n",
    "# sweep_config = {\n",
    "#     'method': 'bayes',  # 'random' or 'grid' or 'bayes'\n",
    "#     'metric': {\n",
    "#       'name': 'accuracy',\n",
    "#       'goal': 'maximize'   \n",
    "#     },\n",
    "#     'parameters': {\n",
    "#         'learning_rate': {\n",
    "#             'min': 0.05,\n",
    "#             'max': 0.5\n",
    "#         },\n",
    "#         'max_depth': {\n",
    "#             'min': 5,\n",
    "#             'max': 15\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"Dacon-loan-rating\")\n",
    "\n",
    "# # sweep 실행\n",
    "# def train():\n",
    "#     # wandb.init()을 사용하여 새로운 실행을 시작\n",
    "#     with wandb.init() as run:\n",
    "#         model = CatBoostClassifier(\n",
    "#             learning_rate=run.config.learning_rate,\n",
    "#             max_depth=run.config.max_depth,\n",
    "#             task_type='GPU',\n",
    "#             bootstrap_type='Bernoulli',\n",
    "#             verbose=100\n",
    "#         )\n",
    "        \n",
    "#         model.fit(train_x, train_y)\n",
    "#         y_pred = model.predict(valid_x)\n",
    "#         accuracy = f1_score(valid_y, y_pred,average='macro')\n",
    "        \n",
    "#         # log the metric\n",
    "#         wandb.log({\"accuracy\": accuracy})\n",
    "#         wandb.log({\"learning_rate\": run.config.learning_rate})\n",
    "#         wandb.log({\"max_depth\": run.config.max_depth})\n",
    "        \n",
    "\n",
    "# wandb.agent(sweep_id, function=train)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2451fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_categorical(y, num_classes=None, dtype=\"float32\"):\n",
    "    y = np.array(y, dtype=\"int\")\n",
    "    input_shape = y.shape\n",
    "\n",
    "    # Shrink the last dimension if the shape is (..., 1).\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "\n",
    "    y = y.reshape(-1)\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n",
    "\n",
    "cat_models={}\n",
    "\n",
    "def cat_kfold(max_depth, learning_rate, random_seed):\n",
    "    \n",
    "    folds=StratifiedKFold(n_splits=8, shuffle=True, random_state=55)\n",
    "    outcomes=[]\n",
    "    sub=np.zeros((test.shape[0], 7))  \n",
    "    \n",
    "    for seed in random_seed:\n",
    "        for n_fold, (train_index, val_index) in enumerate(folds.split(train_x, train_y)):\n",
    "            print(f'===================================={n_fold+1}============================================')\n",
    "            \n",
    "            X_train, X_val = train_x.iloc[train_index], train_x.iloc[val_index]\n",
    "            y_train, y_val = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "\n",
    "            # early_stopping 50에서 가장 좋은 점수를 내는 learning_rate를 활용\n",
    "            cat = CatBoostClassifier(n_estimators=3000, max_depth=max_depth, random_seed=seed, learning_rate=learning_rate, bootstrap_type ='Bernoulli')\n",
    "            cat.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                  early_stopping_rounds=50,\n",
    "                  cat_features=categorical_features,\n",
    "                  verbose=100)\n",
    "\n",
    "            cat_models[n_fold] = cat\n",
    "\n",
    "            # val 데이터 예측\n",
    "            predictions = cat.predict_proba(X_val)\n",
    "            # test 데이터 예측\n",
    "            test_predictions = cat.predict_proba(test)\n",
    "\n",
    "            # val 데이터 예측 logloss 값 저장\n",
    "            logloss=log_loss(to_categorical(y_val), predictions)\n",
    "            outcomes.append(logloss)\n",
    "            print(f\"FOLD {n_fold+1} : logloss:{logloss}\")\n",
    "\n",
    "            # test 데이터 예측 결과 종합\n",
    "            # 최종 적으로는 kolds 횟수 만큼 나눠서 평균 값을 활용\n",
    "            sub+=test_predictions\n",
    "            print(f'================================================================================\\n\\n')\n",
    "\n",
    "    # 저장된 val 데이터 예측 logloss 값의 평균 값으로 성능을 비교\n",
    "    mean_outcome=np.mean(outcomes)\n",
    "    print(\"Mean:{}\".format(mean_outcome))\n",
    "    \n",
    "    return sub/(folds.n_splits * len(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = cat_kfold(5, 0.07556, [1042])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='NanumGothic')\n",
    "def plot_feature_importance(importance, names, model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "\n",
    "plot_feature_importance(cat_models[0].get_feature_importance(), train_x.columns,'CatBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b72aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CatBoostClassifier(n_estimators=1000, learning_rate=0.07556, max_depth=5, verbose=100, task_type='GPU', bootstrap_type ='Bernoulli')\n",
    "model = model.fit(train_x, train_y, cat_features=categorical_features, early_stopping_rounds=50, eval_set=[(valid_x, valid_y)])\n",
    "pred = model.predict(valid_x)\n",
    "evaluate = f1_score(valid_y, pred, average=\"macro\")\n",
    "\n",
    "#_, evaluate, model = ml_train_valid(model, f1_score, {\"average\": \"macro\"}, train_x, train_y, valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\"valid score:\", evaluate)\n",
    "pred = ml_predict(model, test)\n",
    "submission['대출등급'] = ord_dict[\"대출등급\"].inverse_transform(pred.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "print(submission)\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%y%m%d.%H%M\")\n",
    "print(current_datetime)\n",
    "\n",
    "submission.to_csv('cat'+current_datetime+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
